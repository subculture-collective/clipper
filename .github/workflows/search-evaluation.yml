name: Search Evaluation

on:
  schedule:
    # Run nightly at 3 AM UTC
    - cron: '0 3 * * *'
  workflow_dispatch:
    # Allow manual triggering
  push:
    paths:
      - 'backend/internal/services/search*.go'
      - 'backend/internal/services/hybrid_search*.go'
      - 'backend/testdata/search_evaluation_dataset.yaml'
      - 'backend/pkg/opensearch/**'
      - '.github/workflows/search-evaluation.yml'

permissions:
  contents: read

jobs:
  evaluate-search:
    name: Search Quality Evaluation
    runs-on: ubuntu-latest
    permissions:
      contents: read
      pull-requests: write
    steps:
      - uses: actions/checkout@v4

      - name: Set up Go
        uses: actions/setup-go@v5
        with:
          go-version: '1.22.x'

      - name: Cache Go modules
        uses: actions/cache@v4
        with:
          path: ~/go/pkg/mod
          key: ${{ runner.os }}-go-${{ hashFiles('**/go.sum') }}
          restore-keys: |
            ${{ runner.os }}-go-

      - name: Build evaluation tool
        run: |
          cd backend
          go build -o bin/evaluate-search ./cmd/evaluate-search

      - name: Run search evaluation
        run: |
          cd backend
          ./bin/evaluate-search -verbose -output search-evaluation-results.json
        continue-on-error: true

      - name: Display results summary
        if: always()
        run: |
          cd backend
          if [ -f search-evaluation-results.json ]; then
            echo "Search Evaluation Results:"
            echo "=================================="
            # Extract and display key metrics using jq
            echo ""
            echo "Aggregate Metrics:"
            jq -r '.aggregate_metrics | 
              "  nDCG@5:          " + (.mean_ndcg_at_5 | tostring) + "\n" +
              "  nDCG@10:         " + (.mean_ndcg_at_10 | tostring) + "\n" +
              "  MRR:             " + (.mean_mrr | tostring) + "\n" +
              "  Precision@5:     " + (.mean_precision_at_5 | tostring) + "\n" +
              "  Precision@10:    " + (.mean_precision_at_10 | tostring) + "\n" +
              "  Precision@20:    " + (.mean_precision_at_20 | tostring) + "\n" +
              "  Recall@5:        " + (.mean_recall_at_5 | tostring) + "\n" +
              "  Recall@10:       " + (.mean_recall_at_10 | tostring) + "\n" +
              "  Recall@20:       " + (.mean_recall_at_20 | tostring) + "\n" +
              "  Query Count:     " + (.query_count | tostring)
            ' search-evaluation-results.json
            echo ""
          else
            echo "No results file found"
          fi

      - name: Upload evaluation results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: search-evaluation-results-${{ github.run_number }}
          path: backend/search-evaluation-results.json
          retention-days: 90

      - name: Check for critical failures
        run: |
          cd backend
          if [ -f search-evaluation-results.json ]; then
            # Check if any metrics are in critical status
            critical_count=$(jq '[.status[] | select(. == "critical")] | length' search-evaluation-results.json)
            if [ "$critical_count" -gt 0 ]; then
              echo "❌ $critical_count metrics failed critical thresholds"
              jq -r '.status | to_entries[] | select(.value == "critical") | "  - " + .key + ": " + .value' search-evaluation-results.json
              exit 1
            else
              echo "✅ All metrics passed or are at warning level"
            fi
          fi

      - name: Comment on PR (if applicable)
        if: github.event_name == 'pull_request' && always()
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            if (fs.existsSync('backend/search-evaluation-results.json')) {
              const results = JSON.parse(fs.readFileSync('backend/search-evaluation-results.json', 'utf8'));
              const metrics = results.aggregate_metrics;
              const status = results.status || {};
              
              let statusEmoji = (s) => {
                if (s === 'pass') return '✅';
                if (s === 'warning') return '⚠️';
                if (s === 'critical') return '❌';
                return '❓';
              };
              
              let comment = `## Search Evaluation Results\n\n`;
              comment += `### Aggregate Metrics\n\n`;
              comment += `| Metric | Value | Status |\n`;
              comment += `|--------|-------|--------|\n`;
              comment += `| nDCG@5 | ${metrics.mean_ndcg_at_5.toFixed(4)} | ${statusEmoji(status.ndcg_at_5)} |\n`;
              comment += `| nDCG@10 | ${metrics.mean_ndcg_at_10.toFixed(4)} | ${statusEmoji(status.ndcg_at_10)} |\n`;
              comment += `| MRR | ${metrics.mean_mrr.toFixed(4)} | ${statusEmoji(status.mrr)} |\n`;
              comment += `| Precision@5 | ${metrics.mean_precision_at_5.toFixed(4)} | ${statusEmoji(status.precision_at_5)} |\n`;
              comment += `| Precision@10 | ${metrics.mean_precision_at_10.toFixed(4)} | ${statusEmoji(status.precision_at_10)} |\n`;
              comment += `| Precision@20 | ${metrics.mean_precision_at_20.toFixed(4)} | ${statusEmoji(status.precision_at_20)} |\n`;
              comment += `| Recall@5 | ${metrics.mean_recall_at_5.toFixed(4)} | ${statusEmoji(status.recall_at_5)} |\n`;
              comment += `| Recall@10 | ${metrics.mean_recall_at_10.toFixed(4)} | ${statusEmoji(status.recall_at_10)} |\n`;
              comment += `| Recall@20 | ${metrics.mean_recall_at_20.toFixed(4)} | ${statusEmoji(status.recall_at_20)} |\n`;
              comment += `\n**Total Queries:** ${metrics.query_count}\n`;
              
              github.rest.issues.createComment({
                issue_number: context.issue.number,
                owner: context.repo.owner,
                repo: context.repo.repo,
                body: comment
              });
            }
