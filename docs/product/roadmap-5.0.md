---
title: "Roadmap 5.0 ‚Äî Testing, Infrastructure, and Platform Excellence"
summary: "Post-feature-freeze roadmap focused on testing coverage, infrastructure hardening, mobile parity, and documentation excellence following complete feature inventory audit."
tags: ["product", "roadmap", "planning", "testing", "infrastructure"]
owner: "team-core"
status: "active"
version: "5.0"
last_reviewed: 2025-12-24
---

# Roadmap 5.0: Testing, Infrastructure & Platform Excellence

**Target Completion**: Q1-Q2 2026
**Status**: Active
**Created**: December 24, 2025
**Supersedes**: Roadmap 4.0 (feature development roadmap)

---

## Overview

Roadmap 5.0 represents a strategic shift from feature development to **platform maturity and excellence**. Following a comprehensive feature inventory audit that documented 66 platform features with 97% completion, this roadmap focuses on closing critical gaps in:

- **Testing Infrastructure** (E2E, integration, scheduler tests)
- **Mobile Feature Parity** (MFA UI, telemetry, performance)
- **Analytics & ML Enhancement** (algorithm tuning, classification)
- **Documentation Excellence** (Obsidian vault, admin dashboard docs)
- **Infrastructure Hardening** (Kubernetes, auto-scaling, monitoring)

This roadmap builds upon Roadmap 4.0's sequential development approach while pivoting to **quality, reliability, and operational excellence**.

---

## Strategic Context

### What Changed Since Roadmap 4.0?

**Roadmap 4.0** focused on feature delivery across 13 phases covering security, infrastructure, payments, social features, and launch preparation. Most features are now implemented.

**Roadmap 5.0** shifts focus to:
1. **Testing coverage** from current ~60% to 90%+
2. **Mobile parity** with web platform (6 missing features identified)
3. **Infrastructure automation** for scale and reliability
4. **Documentation standardization** for team velocity
5. **ML/Analytics enhancement** for personalization and safety

### Feature Inventory Findings

The December 2024 audit revealed:
- ‚úÖ **64 features complete** (97%)
- üü° **2 features partial** (Clip Scraper, Recommendations)
- ‚ö†Ô∏è **1 feature broken** (Scheduler Tests)
- **Critical gaps**: E2E tests, mobile MFA UI, scheduler reliability, documentation tooling

### Success Metrics

By end of Q2 2026:
- **Testing**: 90%+ code coverage, all E2E flows automated
- **Mobile**: Feature parity with web, 1000+ MAU
- **Performance**: p95 latency < 200ms, 99.9% uptime
- **Documentation**: 100% API coverage, zero stale docs
- **Infrastructure**: Zero-downtime deployments, auto-scaling operational

---

## Development Order (Phases)

### Phase 0: Foundation & Planning

**Duration**: Week 1
**Owner**: Engineering Lead

- **#805** Roadmap 5.0 Master Tracker
- **#834** Feature Inventory Issue Creation (25 audit issues)
- **#835** Testing Strategy Document
- **#836** Infrastructure Modernization RFC

**Goals**:
- All feature audit issues created and prioritized
- Testing strategy approved by team
- Infrastructure roadmap aligned with DevOps

---

### Phase 1: Testing Infrastructure (Critical)

**Duration**: 4-6 weeks
**Priority**: P0 - Blocking
**Owner**: QA + Backend Team

#### 1.1 End-to-End Testing Suite

**Epic**: Comprehensive E2E Testing Infrastructure
**Status**: Not Started
**Effort**: 60-80 hours

**Child Issues**:

1. **#806 - Playwright E2E Framework Setup**
   - **Priority**: P0
   - **Effort**: 12-16 hours
   - **Description**: Set up Playwright testing framework with TypeScript, configure test environments (local, CI), establish page object model pattern, implement fixtures and test data factories.
   - **Acceptance Criteria**:
     - [ ] Playwright installed and configured in `/frontend/e2e/`
     - [ ] Base test utilities and page objects created
     - [ ] CI pipeline runs E2E tests on PRs
     - [ ] Test reports generated and archived
     - [ ] Screenshot/video capture on failures
   - **Dependencies**: None
   - **Tags**: `testing`, `e2e`, `infrastructure`

2. **#807 - Clip Submission E2E Flow**
   - **Priority**: P0
   - **Effort**: 16-24 hours
   - **Description**: Implement comprehensive E2E tests for clip submission workflow covering authentication, rate limiting, validation, approval queue, and notification flows. Test both success and error paths.
   - **Acceptance Criteria**:
     - [ ] Test covers full submission flow (login ‚Üí submit ‚Üí approval ‚Üí notification)
     - [ ] Rate limiting validation tested (10 submissions/hour limit)
     - [ ] Duplicate clip detection tested
     - [ ] Admin approval workflow tested
     - [ ] User notification on approval/rejection verified
     - [ ] Error handling for invalid Twitch URLs
     - [ ] Test runs in < 2 minutes
   - **Dependencies**: #TBD (Playwright setup)
   - **Tags**: `testing`, `e2e`, `clips`

3. **#808 - Authentication & Session E2E Tests**
   - **Priority**: P0
   - **Effort**: 12-16 hours
   - **Description**: E2E tests for Twitch OAuth flow, session management, MFA flows, token refresh, and logout scenarios.
   - **Acceptance Criteria**:
     - [ ] OAuth login flow tested end-to-end
     - [ ] MFA enrollment and challenge flows tested
     - [ ] Session persistence verified
     - [ ] Token refresh tested
     - [ ] Logout and session cleanup verified
     - [ ] Concurrent session handling tested
   - **Dependencies**: #TBD (Playwright setup)
   - **Tags**: `testing`, `e2e`, `auth`

4. **#809 - Search & Discovery E2E Tests**
   - **Priority**: P1
   - **Effort**: 12-16 hours
   - **Description**: E2E tests for search functionality including full-text search, semantic search, filters, suggestions, and search history.
   - **Acceptance Criteria**:
     - [ ] Basic text search tested
     - [ ] Filter combinations tested (tags, games, broadcasters)
     - [ ] Search suggestions tested
     - [ ] Search history persistence tested
     - [ ] Empty results handling tested
     - [ ] Performance benchmarked (< 500ms p95)
   - **Dependencies**: #TBD (Playwright setup)
   - **Tags**: `testing`, `e2e`, `search`

5. **#810 - Premium Subscription E2E Flow**
   - **Priority**: P1
   - **Effort**: 16-24 hours
   - **Description**: E2E tests for Stripe subscription flows including checkout, payment success/failure, webhook handling, subscription management, and cancellation.
   - **Acceptance Criteria**:
     - [ ] Stripe checkout flow tested (test mode)
     - [ ] Successful payment flow verified
     - [ ] Failed payment handling tested
     - [ ] Subscription activation verified
     - [ ] Customer portal tested
     - [ ] Cancellation flow tested
     - [ ] Webhook event handling verified
   - **Dependencies**: #TBD (Playwright setup)
   - **Tags**: `testing`, `e2e`, `premium`, `stripe`

6. **#811 - Social Features E2E Tests**
   - **Priority**: P2
   - **Effort**: 12-16 hours
   - **Description**: E2E tests for comments, voting, following, playlists, and user interactions.
   - **Acceptance Criteria**:
     - [ ] Comment posting and threading tested
     - [ ] Voting (upvote/downvote) tested
     - [ ] Follow/unfollow flows tested
     - [ ] Playlist creation and management tested
     - [ ] Blocking users tested
     - [ ] Rate limiting tested
   - **Dependencies**: #TBD (Playwright setup)
   - **Tags**: `testing`, `e2e`, `social`

#### 1.2 Integration Testing

**Epic**: Comprehensive Integration Test Coverage
**Status**: Not Started
**Effort**: 40-60 hours

**Child Issues**:

7. **#812 - API Integration Test Framework**
   - **Priority**: P0
   - **Effort**: 12-16 hours
   - **Description**: Set up API integration testing framework using Go testing with real database, Redis, and external service mocks. Configure test database setup/teardown, seed data, and parallel test execution.
   - **Acceptance Criteria**:
     - [ ] Test framework supports test database lifecycle
     - [ ] Fixtures and factories for test data
     - [ ] External service mocking (Twitch API, SendGrid, etc.)
     - [ ] Parallel test execution supported
     - [ ] Coverage reporting configured
     - [ ] CI integration complete
   - **Dependencies**: None
   - **Tags**: `testing`, `integration`, `backend`

8. **#813 - Clip Management Integration Tests**
   - **Priority**: P0
   - **Effort**: 8-12 hours
   - **Description**: Integration tests covering clip CRUD operations, scraping, mirroring, metadata enrichment, and vote aggregation with real database transactions.
   - **Acceptance Criteria**:
     - [ ] Clip creation with Twitch metadata tested
     - [ ] Clip scraping and sync tested
     - [ ] Vote aggregation tested
     - [ ] Favorite management tested
     - [ ] Related clips algorithm tested
     - [ ] Visibility controls tested
   - **Dependencies**: #TBD (API integration framework)
   - **Tags**: `testing`, `integration`, `clips`

9. **#814 - User & Auth Integration Tests**
   - **Priority**: P0
   - **Effort**: 8-12 hours
   - **Description**: Integration tests for user lifecycle, OAuth flows, session management, role assignment, and permission checks.
   - **Acceptance Criteria**:
     - [ ] User registration and profile setup tested
     - [ ] OAuth token handling tested
     - [ ] Role-based permission checks tested
     - [ ] MFA enrollment and verification tested
     - [ ] Account deletion and data export tested
   - **Dependencies**: #TBD (API integration framework)
   - **Tags**: `testing`, `integration`, `auth`

10. **#815 - Subscription & Payment Integration Tests**
    - **Priority**: P1
    - **Effort**: 12-16 hours
    - **Description**: Integration tests for Stripe subscription lifecycle, webhook processing, entitlement sync, and payment edge cases.
    - **Acceptance Criteria**:
      - [ ] Subscription creation tested
      - [ ] Webhook event processing tested
      - [ ] Entitlement activation/revocation tested
      - [ ] Payment failure handling tested
      - [ ] Subscription cancellation tested
      - [ ] Prorations tested
    - **Dependencies**: #TBD (API integration framework)
    - **Tags**: `testing`, `integration`, `stripe`

#### 1.3 Scheduler & Background Job Testing

**Epic**: Scheduler Reliability & Testing
**Status**: ‚ö†Ô∏è Broken (scheduler tests failing)
**Effort**: 24-32 hours

**Child Issues**:

11. **#816 - Fix Failing Scheduler Tests**
    - **Priority**: P0
    - **Effort**: 8-12 hours
    - **Description**: Investigate and fix currently failing scheduler tests in `clip_sync_scheduler_test.go` and related scheduler test files. Address race conditions, timing issues, and test isolation problems.
    - **Acceptance Criteria**:
      - [ ] All existing scheduler tests pass reliably
      - [ ] Race conditions eliminated
      - [ ] Test isolation ensured (no shared state)
      - [ ] Deterministic test execution
      - [ ] CI runs scheduler tests without flakiness
    - **Dependencies**: None
    - **Tags**: `testing`, `bug`, `scheduler`, `P0`

12. **#817 - Scheduler Test Framework Enhancement**
    - **Priority**: P1
    - **Effort**: 8-12 hours
    - **Description**: Enhance scheduler testing framework with better time mocking, job execution verification, and error handling validation.
    - **Acceptance Criteria**:
      - [ ] Time mocking utilities for cron testing
      - [ ] Job execution tracking and verification
      - [ ] Error injection and recovery testing
      - [ ] Concurrency testing utilities
      - [ ] Performance benchmarks for schedulers
    - **Dependencies**: #TBD (Fix failing tests)
    - **Tags**: `testing`, `scheduler`, `infrastructure`

13. **#818 - Background Job Monitoring & Alerting**
    - **Priority**: P1
    - **Effort**: 8-12 hours
    - **Description**: Implement comprehensive monitoring and alerting for all background jobs including execution time, failure rates, and job queue depth.
    - **Acceptance Criteria**:
      - [ ] Prometheus metrics for all schedulers
      - [ ] Grafana dashboard for job monitoring
      - [ ] Alerts for job failures (3+ consecutive)
      - [ ] Alerts for job execution delays (>2x expected)
      - [ ] Dead letter queue monitoring
    - **Dependencies**: None
    - **Tags**: `monitoring`, `scheduler`, `observability`

#### 1.4 Load & Performance Testing

**Epic**: Performance Validation & Benchmarking
**Status**: Partial (basic load tests exist)
**Effort**: 32-48 hours

**Child Issues**:

14. **#819 - k6 Load Testing Framework**
    - **Priority**: P1
    - **Effort**: 12-16 hours
    - **Description**: Set up comprehensive k6 load testing framework with scenarios for key user flows, ramp-up/sustained load profiles, and performance reporting.
    - **Acceptance Criteria**:
      - [ ] k6 installed and configured
      - [ ] Test scenarios for major endpoints
      - [ ] CI integration for nightly load tests
      - [ ] Performance regression detection
      - [ ] HTML reports generated
      - [ ] SLO validation automated
    - **Dependencies**: None
    - **Tags**: `testing`, `performance`, `load-testing`

15. **#820 - API Endpoint Performance Benchmarks**
    - **Priority**: P1
    - **Effort**: 12-16 hours
    - **Description**: Establish performance baselines and benchmarks for all critical API endpoints with p50/p95/p99 latency targets.
    - **Acceptance Criteria**:
      - [ ] Benchmarks for top 20 endpoints
      - [ ] Performance targets documented
      - [ ] Database query profiling
      - [ ] N+1 query detection
      - [ ] Cache hit rate monitoring
      - [ ] Regression alerts configured
    - **Dependencies**: #TBD (k6 framework)
    - **Tags**: `testing`, `performance`, `benchmarking`

16. **#821 - Stress & Soak Testing**
    - **Priority**: P2
    - **Effort**: 8-12 hours
    - **Description**: Implement stress tests (beyond expected capacity) and soak tests (sustained load over 24h) to identify breaking points and memory leaks.
    - **Acceptance Criteria**:
      - [ ] Stress test identifies breaking points
      - [ ] Soak test runs for 24+ hours
      - [ ] Memory leak detection
      - [ ] Resource exhaustion testing
      - [ ] Recovery behavior validated
    - **Dependencies**: #TBD (k6 framework)
    - **Tags**: `testing`, `performance`, `reliability`

---

### Phase 2: Mobile Feature Parity

**Duration**: 4-6 weeks
**Priority**: P1 - High
**Owner**: Mobile Team

#### 2.1 Mobile MFA Implementation

**Epic**: Multi-Factor Authentication for Mobile
**Status**: Not Started
**Effort**: 24-32 hours

**Child Issues**:

17. **#822 - Mobile MFA Enrollment UI**
    - **Priority**: P0
    - **Effort**: 12-16 hours
    - **Description**: Implement MFA enrollment flow in React Native app including QR code scanning for TOTP, backup codes generation, and email OTP fallback.
    - **Acceptance Criteria**:
      - [ ] QR code scanner for TOTP setup
      - [ ] Manual key entry option
      - [ ] Backup codes display and storage
      - [ ] Email OTP fallback flow
      - [ ] Device trust management
      - [ ] iOS and Android parity
    - **Dependencies**: None (backend exists)
    - **Tags**: `mobile`, `mfa`, `security`, `ios`, `android`

18. **#823 - Mobile MFA Challenge UI**
    - **Priority**: P0
    - **Effort**: 12-16 hours
    - **Description**: Implement MFA challenge screens for login, sensitive actions, and backup code entry with biometric authentication integration.
    - **Acceptance Criteria**:
      - [ ] TOTP code entry screen
      - [ ] Email OTP entry screen
      - [ ] Backup code entry screen
      - [ ] Biometric authentication integration
      - [ ] Remember device option
      - [ ] Error handling and retry logic
    - **Dependencies**: #TBD (MFA enrollment UI)
    - **Tags**: `mobile`, `mfa`, `security`

#### 2.2 Mobile Telemetry & Analytics

**Epic**: Mobile Analytics & Crash Reporting
**Status**: Not Started
**Effort**: 20-28 hours

**Child Issues**:

19. **#824 - PostHog SDK Integration**
    - **Priority**: P1
    - **Effort**: 8-12 hours
    - **Description**: Integrate PostHog analytics SDK for event tracking, user properties, and feature flags in mobile apps.
    - **Acceptance Criteria**:
      - [ ] PostHog SDK installed (iOS + Android)
      - [ ] Core events instrumented (40+ events)
      - [ ] User properties tracked
      - [ ] Screen view tracking
      - [ ] Session tracking
      - [ ] Privacy controls respected
    - **Dependencies**: None
    - **Tags**: `mobile`, `analytics`, `telemetry`

20. **#825 - Sentry Crash Reporting**
    - **Priority**: P1
    - **Effort**: 6-8 hours
    - **Description**: Integrate Sentry for crash reporting, error tracking, and performance monitoring in mobile apps.
    - **Acceptance Criteria**:
      - [ ] Sentry SDK configured
      - [ ] Crashes automatically reported
      - [ ] Source maps uploaded
      - [ ] Release tracking configured
      - [ ] User context attached to errors
      - [ ] Performance monitoring enabled
    - **Dependencies**: None
    - **Tags**: `mobile`, `monitoring`, `crash-reporting`

21. **#826 - Mobile Analytics Dashboard**
    - **Priority**: P2
    - **Effort**: 6-8 hours
    - **Description**: Create PostHog dashboards for mobile-specific metrics including screen views, user flows, retention, and crash-free sessions.
    - **Acceptance Criteria**:
      - [ ] User flow funnels configured
      - [ ] Retention cohorts defined
      - [ ] Screen view tracking dashboard
      - [ ] Crash-free sessions metric
      - [ ] Daily active users tracking
    - **Dependencies**: #TBD (PostHog integration)
    - **Tags**: `mobile`, `analytics`, `dashboard`

#### 2.3 Mobile E2E Testing

**Epic**: Mobile E2E Test Coverage
**Status**: Not Started
**Effort**: 40-60 hours

**Child Issues**:

22. **#827 - Detox E2E Framework Setup**
    - **Priority**: P1
    - **Effort**: 16-24 hours
    - **Description**: Set up Detox E2E testing framework for React Native with iOS and Android simulators, CI integration, and test infrastructure.
    - **Acceptance Criteria**:
      - [ ] Detox installed and configured
      - [ ] iOS simulator setup automated
      - [ ] Android emulator setup automated
      - [ ] CI pipeline runs mobile E2E tests
      - [ ] Screenshot/video capture on failures
      - [ ] Test reports generated
    - **Dependencies**: None
    - **Tags**: `mobile`, `testing`, `e2e`, `infrastructure`

23. **#828 - Mobile Critical Flow E2E Tests**
    - **Priority**: P1
    - **Effort**: 24-36 hours
    - **Description**: Implement E2E tests for critical mobile flows including authentication, clip viewing, search, submission, and profile management.
    - **Acceptance Criteria**:
      - [ ] OAuth login flow tested
      - [ ] Clip feed scrolling tested
      - [ ] Clip detail and playback tested
      - [ ] Search functionality tested
      - [ ] Clip submission tested
      - [ ] Profile and settings tested
      - [ ] Tests run on both iOS and Android
    - **Dependencies**: #TBD (Detox setup)
    - **Tags**: `mobile`, `testing`, `e2e`

#### 2.4 Mobile Performance Optimization

**Epic**: Mobile Performance & UX Polish
**Status**: Partial
**Effort**: 28-40 hours

**Child Issues**:

24. **#829 - Feed Performance Optimization**
    - **Priority**: P1
    - **Effort**: 12-16 hours
    - **Description**: Eliminate N+1 media URL fetches by batching API requests, implement virtualized lists, and optimize image loading with caching.
    - **Acceptance Criteria**:
      - [ ] Batch media URL API implemented
      - [ ] FlashList virtualization working
      - [ ] Image caching with react-native-fast-image
      - [ ] Feed initial render < 1.5s (p95)
      - [ ] Network requests reduced by 70%+
      - [ ] Smooth 60fps scrolling
    - **Dependencies**: Backend batch API endpoint
    - **Tags**: `mobile`, `performance`, `optimization`

25. **#830 - Video Playback Polish**
    - **Priority**: P2
    - **Effort**: 12-16 hours
    - **Description**: Implement quality selection, Picture-in-Picture QA, background playback, and memory profiling for video player.
    - **Acceptance Criteria**:
      - [ ] Quality selection UI (auto/720p/480p/360p)
      - [ ] PiP working on iOS and Android
      - [ ] Background audio playback
      - [ ] Memory profiling completed
      - [ ] No memory leaks detected
      - [ ] Player controls responsive at 60fps
    - **Dependencies**: None
    - **Tags**: `mobile`, `video`, `performance`

26. **#831 - Mobile Deprecation Cleanup**
    - **Priority**: P3
    - **Effort**: 4-8 hours
    - **Description**: Remove React Native pointerEvents deprecation warnings by updating to modern prop equivalents.
    - **Acceptance Criteria**:
      - [ ] Audit all pointerEvents usage
      - [ ] Replace with RN 0.81+ equivalents
      - [ ] Verify touch interactions on iOS/Android
      - [ ] Zero deprecation warnings at runtime
    - **Dependencies**: None
    - **Tags**: `mobile`, `tech-debt`, `cleanup`

---

### Phase 3: Analytics & ML Enhancement

**Duration**: 6-8 weeks
**Priority**: P2 - Medium
**Owner**: Data Team

#### 3.1 Search Ranking Tuning

**Epic**: Search Quality & Relevance Improvement
**Status**: Partial
**Effort**: 32-48 hours

**Child Issues**:

27. **#837 - Search Relevance Evaluation Framework**
    - **Priority**: P1
    - **Effort**: 16-24 hours
    - **Description**: Build evaluation framework for search quality using nDCG, precision@k, and user engagement metrics with labeled test dataset.
    - **Acceptance Criteria**:
      - [ ] Test dataset with 500+ labeled queries
      - [ ] nDCG@10 metric implementation
      - [ ] Precision/Recall@5/10/20 metrics
      - [ ] A/B testing framework for ranking changes
      - [ ] Automated evaluation in CI
      - [ ] Reporting dashboard
    - **Dependencies**: None
    - **Tags**: `search`, `analytics`, `ml`, `evaluation`

28. **#838 - Hybrid Search Weight Optimization**
    - **Priority**: P1
    - **Effort**: 16-24 hours
    - **Description**: Optimize BM25 vs. vector similarity weights using grid search and user engagement data to maximize search relevance.
    - **Acceptance Criteria**:
      - [ ] Current baseline metrics established
      - [ ] Grid search over weight combinations
      - [ ] User engagement analysis (CTR, dwell time)
      - [ ] Optimal weights deployed to production
      - [ ] nDCG@10 improved by 10%+
      - [ ] Documentation updated
    - **Dependencies**: #TBD (Evaluation framework)
    - **Tags**: `search`, `optimization`, `ml`

#### 3.2 Recommendation Engine Tuning

**Epic**: Personalized Recommendation Quality
**Status**: Partial
**Effort**: 40-60 hours

**Child Issues**:

29. **#839 - Recommendation Algorithm Evaluation**
    - **Priority**: P2
    - **Effort**: 16-24 hours
    - **Description**: Establish evaluation metrics and benchmarks for recommendation quality including diversity, serendipity, and user satisfaction.
    - **Acceptance Criteria**:
      - [ ] Metrics: precision@k, recall@k, diversity
      - [ ] Serendipity score definition
      - [ ] User satisfaction proxy (engagement time)
      - [ ] Cold start performance metrics
      - [ ] Baseline measurements documented
      - [ ] Evaluation runs nightly in CI
    - **Dependencies**: None
    - **Tags**: `recommendations`, `ml`, `evaluation`

30. **#840 - Collaborative Filtering Optimization**
    - **Priority**: P2
    - **Effort**: 16-24 hours
    - **Description**: Tune collaborative filtering algorithm parameters and implement hybrid approach combining content-based and collaborative signals.
    - **Acceptance Criteria**:
      - [ ] Current algorithm performance baselined
      - [ ] Parameter grid search completed
      - [ ] Hybrid approach implemented
      - [ ] A/B test comparing approaches
      - [ ] Production deployment with rollback plan
      - [ ] Precision@10 improved by 15%+
    - **Dependencies**: #TBD (Recommendation evaluation)
    - **Tags**: `recommendations`, `ml`, `optimization`

31. **#841 - Cold Start Handling Improvements**
    - **Priority**: P2
    - **Effort**: 8-12 hours
    - **Description**: Improve recommendations for new users and new content using content-based features, trending signals, and popularity-based fallbacks.
    - **Acceptance Criteria**:
      - [ ] New user onboarding flow with preferences
      - [ ] Content-based features extracted (tags, categories)
      - [ ] Trending algorithm for cold content
      - [ ] Fallback to popularity when needed
      - [ ] Cold start metrics improved by 20%+
    - **Dependencies**: #TBD (Collaborative filtering)
    - **Tags**: `recommendations`, `ml`, `cold-start`

#### 3.3 ML-Based Moderation

**Epic**: Automated Content Moderation
**Status**: Not Started
**Effort**: 60-80 hours

**Child Issues**:

32. **#842 - Toxic Comment Classification Model**
    - **Priority**: P2
    - **Effort**: 24-32 hours
    - **Description**: Train and deploy toxic comment classification model using Perspective API or custom fine-tuned transformer model.
    - **Acceptance Criteria**:
      - [ ] Model trained on labeled dataset (10k+ examples)
      - [ ] Precision/Recall > 85% on test set
      - [ ] False positive rate < 5%
      - [ ] API endpoint for inference
      - [ ] Integration with comment submission
      - [ ] Human-in-the-loop review queue
    - **Dependencies**: None
    - **Tags**: `moderation`, `ml`, `nlp`

33. **#843 - NSFW Image Detection**
    - **Priority**: P2
    - **Effort**: 16-24 hours
    - **Description**: Integrate NSFW image detection model for thumbnail and image moderation using pre-trained model (e.g., NSFW Detector).
    - **Acceptance Criteria**:
      - [ ] Model deployed as microservice
      - [ ] Thumbnail scanning on upload
      - [ ] Confidence threshold tuning
      - [ ] Auto-flagging of NSFW content
      - [ ] Manual review queue integration
      - [ ] Performance: < 200ms per image
    - **Dependencies**: None
    - **Tags**: `moderation`, `ml`, `computer-vision`

34. **#844 - Abuse Pattern Detection**
    - **Priority**: P2
    - **Effort**: 20-24 hours
    - **Description**: Implement ML-based abuse pattern detection for submission spam, vote manipulation, and coordinated inauthentic behavior.
    - **Acceptance Criteria**:
      - [ ] Feature engineering (velocity, patterns, timestamps)
      - [ ] Anomaly detection model trained
      - [ ] Real-time scoring on user actions
      - [ ] Auto-flagging suspicious accounts
      - [ ] Dashboard for abuse analysts
      - [ ] False positive rate < 2%
    - **Dependencies**: None
    - **Tags**: `moderation`, `ml`, `abuse-detection`

---

### Phase 4: Documentation Excellence

**Duration**: 4-6 weeks
**Priority**: P1 - High
**Owner**: Engineering + Product

#### 4.1 Obsidian Documentation Vault

**Epic**: Full Docs Overhaul ‚Äî Obsidian + Admin Rendering
**Status**: In Progress (Issue #803)
**Effort**: 80-120 hours

**Child Issues** (expanding on #803):

35. **#845 - Docs Structure & Canonical Pages**
    - **Priority**: P0
    - **Effort**: 24-32 hours
    - **Description**: Normalize /docs structure with folder hubs (index.md per folder), create canonical pages, and eliminate duplicates.
    - **Acceptance Criteria**:
      - [ ] Folder structure matches spec from #803
      - [ ] Every folder has index.md hub
      - [ ] Canonical pages created (setup, backend, deployment, product)
      - [ ] Duplicates merged or removed
      - [ ] Legacy docs archived or deleted
      - [ ] Breadcrumb navigation working
    - **Dependencies**: None
    - **Related**: #803
    - **Tags**: `documentation`, `obsidian`, `structure`

36. **#846 - Obsidian Frontmatter & Metadata**
    - **Priority**: P0
    - **Effort**: 16-24 hours
    - **Description**: Add YAML frontmatter to every page with title, tags, area, status, last_reviewed fields and implement Dataview blocks for navigation.
    - **Acceptance Criteria**:
      - [ ] Frontmatter template created
      - [ ] All pages have required frontmatter
      - [ ] Dataview blocks in hub pages
      - [ ] .obsidian/settings configured
      - [ ] Wikilinks working in Obsidian
      - [ ] Tags taxonomy defined
    - **Dependencies**: #TBD (Docs structure)
    - **Related**: #803
    - **Tags**: `documentation`, `obsidian`, `metadata`

37. **#847 - Admin Dashboard Docs Rendering**
    - **Priority**: P0
    - **Effort**: 32-48 hours
    - **Description**: Build admin dashboard docs renderer that parses frontmatter, strips doctoc, handles Dataview blocks, and generates TOC at render-time.
    - **Acceptance Criteria**:
      - [ ] Markdown parser with frontmatter support
      - [ ] DocHeader component renders metadata
      - [ ] Doctoc blocks stripped from output
      - [ ] Dataview blocks rendered as callouts
      - [ ] TOC generated from headings
      - [ ] Wikilinks converted to routes
      - [ ] Sidebar navigation tree
      - [ ] Search functionality
    - **Dependencies**: #TBD (Frontmatter setup)
    - **Related**: #803
    - **Tags**: `documentation`, `frontend`, `admin`

38. **#848 - Docs CI Quality Enforcement**
    - **Priority**: P1
    - **Effort**: 16-24 hours
    - **Description**: Configure markdownlint, cspell, link checker, anchor validator, and orphan detector in CI to enforce docs quality.
    - **Acceptance Criteria**:
      - [ ] markdownlint configured (allow frontmatter, HTML, tables)
      - [ ] cspell ignores wikilinks, block refs, tags
      - [ ] Link checker configured (ignore localhost)
      - [ ] Anchor validator checks markdown links
      - [ ] Orphan detector (BFS from /docs/index.md)
      - [ ] /vault/** excluded from all checks
      - [ ] GitHub Actions workflow added
      - [ ] PR checks failing on violations
    - **Dependencies**: #TBD (Docs structure)
    - **Related**: #803
    - **Tags**: `documentation`, `ci`, `quality`

39. **#849 - Documentation Migration & Cleanup**
    - **Priority**: P1
    - **Effort**: 24-32 hours
    - **Description**: Migrate all existing documentation to new structure, remove doctoc blocks, update internal links, and archive outdated content.
    - **Acceptance Criteria**:
      - [ ] All docs moved to canonical locations
      - [ ] Doctoc blocks removed
      - [ ] Internal links updated
      - [ ] Outdated docs archived to docs/archive/
      - [ ] README.md links updated
      - [ ] No orphaned pages
      - [ ] All CI checks passing
    - **Dependencies**: #TBD (CI enforcement), #TBD (Admin rendering)
    - **Related**: #803
    - **Tags**: `documentation`, `migration`, `cleanup`

#### 4.2 API Documentation Coverage

**Epic**: 100% API Documentation
**Status**: Partial
**Effort**: 40-60 hours

**Child Issues**:

40. **#850 - OpenAPI Spec Completion**
    - **Priority**: P1
    - **Effort**: 24-36 hours
    - **Description**: Complete OpenAPI 3.1 specifications for all 150+ API endpoints with request/response schemas, examples, and error codes.
    - **Acceptance Criteria**:
      - [ ] All endpoints documented in OpenAPI spec
      - [ ] Request/response schemas defined
      - [ ] Example requests/responses included
      - [ ] Error codes and messages documented
      - [ ] Authentication flows documented
      - [ ] Rate limits documented
      - [ ] Swagger UI deployed
      - [ ] Spec validated with openapi-validator
    - **Dependencies**: None
    - **Tags**: `documentation`, `api`, `openapi`

41. **#851 - API Documentation Generator**
    - **Priority**: P2
    - **Effort**: 16-24 hours
    - **Description**: Implement API documentation generator that creates markdown docs from OpenAPI spec and integrates with admin dashboard.
    - **Acceptance Criteria**:
      - [ ] Generator converts OpenAPI ‚Üí Markdown
      - [ ] Code examples in multiple languages
      - [ ] Try-it-out functionality in admin UI
      - [ ] Versioned API docs
      - [ ] Search across API docs
      - [ ] Change log generation
    - **Dependencies**: #TBD (OpenAPI completion)
    - **Tags**: `documentation`, `api`, `automation`

---

### Phase 5: Infrastructure Hardening

**Duration**: 6-8 weeks
**Priority**: P2 - Medium
**Owner**: DevOps Team

#### 5.1 Kubernetes & Orchestration

**Epic**: Kubernetes Production Deployment
**Status**: Not Started
**Effort**: 60-80 hours

**Child Issues**:

42. **#852 - Kubernetes Cluster Setup**
    - **Priority**: P1
    - **Effort**: 24-32 hours
    - **Description**: Set up production Kubernetes cluster with multi-node setup, namespaces, RBAC, network policies, and secrets management.
    - **Acceptance Criteria**:
      - [ ] K8s cluster deployed (GKE, EKS, or AKS)
      - [ ] Namespaces: production, staging, monitoring
      - [ ] RBAC configured with least privilege
      - [ ] Network policies enforced
      - [ ] External secrets operator configured
      - [ ] Ingress controller deployed
      - [ ] SSL/TLS certificates automated
    - **Dependencies**: None
    - **Tags**: `infrastructure`, `kubernetes`, `devops`

43. **#853 - Application Helm Charts**
    - **Priority**: P1
    - **Effort**: 24-32 hours
    - **Description**: Create Helm charts for all Clipper services (backend, frontend, postgres, redis, monitoring) with configurable values and health checks.
    - **Acceptance Criteria**:
      - [ ] Helm charts for backend, frontend, db, cache
      - [ ] Configurable via values.yaml
      - [ ] Health checks and readiness probes
      - [ ] Resource limits and requests defined
      - [ ] HPA (Horizontal Pod Autoscaler) configured
      - [ ] Rolling update strategy configured
      - [ ] Rollback tested
    - **Dependencies**: #TBD (K8s cluster)
    - **Tags**: `infrastructure`, `kubernetes`, `helm`

44. **#854 - Kubernetes Documentation**
    - **Priority**: P2
    - **Effort**: 12-16 hours
    - **Description**: Write comprehensive documentation for Kubernetes deployment, operations, troubleshooting, and disaster recovery.
    - **Acceptance Criteria**:
      - [ ] Deployment guide written
      - [ ] Operations runbook created
      - [ ] Troubleshooting guide with common issues
      - [ ] Disaster recovery procedures documented
      - [ ] Scaling guide written
      - [ ] Cost optimization tips documented
    - **Dependencies**: #TBD (Helm charts)
    - **Tags**: `documentation`, `kubernetes`, `operations`

#### 5.2 Auto-Scaling & Resource Management

**Epic**: Horizontal & Vertical Auto-Scaling
**Status**: Not Started
**Effort**: 32-48 hours

**Child Issues**:

45. **#855 - Horizontal Pod Autoscaling (HPA)**
    - **Priority**: P1
    - **Effort**: 12-16 hours
    - **Description**: Configure HPA for backend and frontend services based on CPU, memory, and custom metrics (requests per second).
    - **Acceptance Criteria**:
      - [ ] HPA configured for backend (2-10 replicas)
      - [ ] HPA configured for frontend (2-8 replicas)
      - [ ] CPU threshold: 70%
      - [ ] Memory threshold: 80%
      - [ ] Custom metric: 1000 req/s per pod
      - [ ] Scale-down stabilization: 5 minutes
      - [ ] Metrics server deployed
      - [ ] Scaling events logged
    - **Dependencies**: #TBD (Helm charts)
    - **Tags**: `infrastructure`, `scaling`, `kubernetes`

46. **#856 - Database Connection Pooling Optimization**
    - **Priority**: P1
    - **Effort**: 8-12 hours
    - **Description**: Optimize database connection pooling with PgBouncer in transaction mode, tune pool sizes based on load testing.
    - **Acceptance Criteria**:
      - [ ] PgBouncer deployed in K8s
      - [ ] Transaction mode configured
      - [ ] Pool sizes tuned (min: 10, max: 50)
      - [ ] Connection metrics exported
      - [ ] Load test validating pooling
      - [ ] Zero connection exhaustion under load
    - **Dependencies**: #TBD (K8s cluster)
    - **Tags**: `infrastructure`, `database`, `performance`

47. **#857 - Resource Quota & Limits**
    - **Priority**: P2
    - **Effort**: 12-20 hours
    - **Description**: Define and enforce resource quotas and limits for all namespaces and pods to prevent resource exhaustion.
    - **Acceptance Criteria**:
      - [ ] ResourceQuotas defined per namespace
      - [ ] LimitRanges configured
      - [ ] Pod resource requests and limits set
      - [ ] OOM killer tested
      - [ ] Resource usage dashboards created
      - [ ] Alerts for quota violations
    - **Dependencies**: #TBD (Helm charts)
    - **Tags**: `infrastructure`, `resources`, `reliability`

#### 5.3 Observability Enhancement

**Epic**: Advanced Monitoring & Alerting
**Status**: Partial
**Effort**: 40-60 hours

**Child Issues**:

48. **#858 - Grafana Dashboards**
    - **Priority**: P1
    - **Effort**: 16-24 hours
    - **Description**: Create comprehensive Grafana dashboards for system health, API performance, database metrics, and business KPIs.
    - **Acceptance Criteria**:
      - [ ] System overview dashboard (CPU, memory, disk, network)
      - [ ] API performance dashboard (latency, throughput, errors)
      - [ ] Database dashboard (connections, queries, locks)
      - [ ] Business KPIs dashboard (DAU, submissions, revenue)
      - [ ] Redis dashboard (hit rate, evictions)
      - [ ] Kubernetes dashboard (pods, nodes, resources)
      - [ ] Dashboards templated and version controlled
    - **Dependencies**: None (Prometheus exists)
    - **Tags**: `monitoring`, `grafana`, `observability`

49. **#859 - Alerting Configuration**
    - **Priority**: P0
    - **Effort**: 16-24 hours
    - **Description**: Configure AlertManager with alert rules for critical system failures, performance degradation, and security incidents.
    - **Acceptance Criteria**:
      - [ ] Critical alerts: API down, DB down, high error rate
      - [ ] Warning alerts: high latency, disk space, memory pressure
      - [ ] Security alerts: authentication failures, rate limit violations
      - [ ] Alert routing to Slack/PagerDuty
      - [ ] Alert silencing and inhibition rules
      - [ ] On-call rotation configured
      - [ ] Runbooks linked to alerts
    - **Dependencies**: #TBD (Grafana dashboards)
    - **Tags**: `monitoring`, `alerting`, `sre`

50. **#860 - Distributed Tracing**
    - **Priority**: P2
    - **Effort**: 8-12 hours
    - **Description**: Implement distributed tracing with OpenTelemetry and Jaeger for request flow visibility across services.
    - **Acceptance Criteria**:
      - [ ] OpenTelemetry SDK integrated
      - [ ] Traces exported to Jaeger
      - [ ] Spans for HTTP requests, DB queries, external APIs
      - [ ] Trace context propagation working
      - [ ] Jaeger UI accessible
      - [ ] Sampling rate configured (10%)
    - **Dependencies**: None
    - **Tags**: `monitoring`, `tracing`, `observability`

#### 5.4 Security & Resilience

**Epic**: Infrastructure Security Hardening
**Status**: Partial
**Effort**: 48-72 hours

**Child Issues**:

51. **#861 - Web Application Firewall (WAF)**
    - **Priority**: P1
    - **Effort**: 16-24 hours
    - **Description**: Deploy and configure WAF (ModSecurity or cloud WAF) with OWASP Core Rule Set for protection against common attacks.
    - **Acceptance Criteria**:
      - [ ] WAF deployed (ModSecurity/AWS WAF/Cloudflare)
      - [ ] OWASP CRS configured
      - [ ] SQL injection protection verified
      - [ ] XSS protection verified
      - [ ] Rate limiting at WAF layer
      - [ ] Logging and monitoring configured
      - [ ] False positive tuning completed
    - **Dependencies**: None
    - **Tags**: `security`, `waf`, `infrastructure`

52. **#862 - DDoS Protection**
    - **Priority**: P1
    - **Effort**: 12-20 hours
    - **Description**: Implement DDoS protection using cloud provider services or Cloudflare with rate limiting and traffic filtering.
    - **Acceptance Criteria**:
      - [ ] DDoS protection service enabled
      - [ ] Rate limiting configured per IP
      - [ ] Geo-blocking for high-risk regions (optional)
      - [ ] Traffic analytics dashboard
      - [ ] Mitigation rules configured
      - [ ] Incident response plan documented
    - **Dependencies**: None
    - **Tags**: `security`, `ddos`, `infrastructure`

53. **#863 - Automated Backup & Recovery**
    - **Priority**: P0
    - **Effort**: 20-28 hours
    - **Description**: Implement automated database backups with Point-in-Time Recovery (PITR), regular restore testing, and documented recovery procedures.
    - **Acceptance Criteria**:
      - [ ] Automated daily backups scheduled
      - [ ] PITR enabled (7-day window)
      - [ ] Backups encrypted at rest
      - [ ] Backups stored in separate region
      - [ ] Monthly restore tests automated
      - [ ] Recovery Time Objective (RTO): < 1 hour
      - [ ] Recovery Point Objective (RPO): < 15 minutes
      - [ ] Disaster recovery runbook created
    - **Dependencies**: None
    - **Tags**: `infrastructure`, `backup`, `disaster-recovery`

---

## Total Issue Summary

### Phase Breakdown

| Phase | Epics | Issues | Total Effort (hours) |
|-------|-------|--------|---------------------|
| **Phase 0: Foundation** | 1 | 4 | 24-32 |
| **Phase 1: Testing Infrastructure** | 4 | 16 | 156-224 |
| **Phase 2: Mobile Feature Parity** | 4 | 10 | 112-160 |
| **Phase 3: Analytics & ML Enhancement** | 3 | 9 | 132-192 |
| **Phase 4: Documentation Excellence** | 2 | 7 | 120-180 |
| **Phase 5: Infrastructure Hardening** | 4 | 12 | 180-260 |
| **TOTAL** | **18** | **58** | **724-1048** |

### Priority Distribution

- **P0 (Critical/Blocking)**: 15 issues
- **P1 (High)**: 29 issues
- **P2 (Medium)**: 13 issues
- **P3 (Low)**: 1 issue

### Area Distribution

- **Testing**: 22 issues (38%)
- **Mobile**: 10 issues (17%)
- **Analytics/ML**: 9 issues (16%)
- **Documentation**: 7 issues (12%)
- **Infrastructure**: 10 issues (17%)

---

## Success Criteria

### Testing Excellence ‚úÖ

- [ ] **Code Coverage**: 90%+ across backend and frontend
- [ ] **E2E Coverage**: All critical user flows automated
- [ ] **Integration Tests**: 100 endpoints covered
- [ ] **Performance Tests**: Nightly load tests in CI
- [ ] **Scheduler Tests**: Zero failing tests, < 1% flakiness

### Mobile Maturity ‚úÖ

- [ ] **Feature Parity**: MFA, telemetry, E2E tests implemented
- [ ] **Performance**: Feed render < 1.5s, 60fps scrolling
- [ ] **Quality**: 99.5%+ crash-free sessions
- [ ] **Adoption**: 1000+ MAU, 4.5+ star rating

### Analytics & Intelligence ‚úÖ

- [ ] **Search Quality**: nDCG@10 > 0.85
- [ ] **Recommendations**: Precision@10 > 0.70
- [ ] **Moderation**: 85%+ precision/recall on toxic content
- [ ] **Insights**: Real-time dashboards for all key metrics

### Documentation Standards ‚úÖ

- [ ] **Obsidian Vault**: 100% docs with frontmatter, zero orphans
- [ ] **API Coverage**: 100% endpoints documented in OpenAPI
- [ ] **CI Enforcement**: Zero broken links, spelling errors, or orphans
- [ ] **Admin Rendering**: Docs browsable in admin dashboard

### Infrastructure Resilience ‚úÖ

- [ ] **Uptime**: 99.9% availability (< 45 min downtime/month)
- [ ] **Performance**: p95 latency < 200ms for all critical endpoints
- [ ] **Security**: WAF + DDoS protection operational
- [ ] **DR**: RTO < 1 hour, RPO < 15 minutes

---

## Timeline & Milestones

### Week 1-2: Foundation (Phase 0)
- Roadmap planning and issue creation
- Testing strategy approval
- Infrastructure RFC

### Week 3-8: Testing Infrastructure (Phase 1)
- **Week 3-4**: E2E framework and critical flows
- **Week 5-6**: Integration tests and scheduler fixes
- **Week 7-8**: Load testing and performance benchmarks

### Week 9-14: Mobile Parity (Phase 2)
- **Week 9-10**: MFA implementation
- **Week 11-12**: Telemetry and E2E testing
- **Week 13-14**: Performance optimization

### Week 15-22: Analytics & ML (Phase 3)
- **Week 15-17**: Search ranking tuning
- **Week 18-20**: Recommendation optimization
- **Week 21-22**: ML moderation deployment

### Week 15-20: Documentation (Phase 4) - Parallel
- **Week 15-16**: Obsidian structure and frontmatter
- **Week 17-18**: Admin rendering and CI
- **Week 19-20**: Migration and API docs

### Week 21-28: Infrastructure (Phase 5) - Parallel
- **Week 21-23**: Kubernetes setup
- **Week 24-25**: Auto-scaling
- **Week 26-27**: Observability enhancement
- **Week 28**: Security hardening

---

## Dependencies & Blockers

### Critical Path

1. **Testing Infrastructure** ‚Üí Mobile E2E, Performance validation
2. **Scheduler Fixes** ‚Üí Background job reliability
3. **Kubernetes Setup** ‚Üí Auto-scaling, Production readiness
4. **Obsidian Docs** ‚Üí Admin rendering, API docs generation

### External Dependencies

- **Cloud Provider**: K8s cluster provisioning (1-2 week lead time)
- **Design Team**: Mobile UI assets, MFA screens (ongoing)
- **Data Team**: Labeled datasets for ML models (4-6 weeks)

### Risk Mitigation

- **Kubernetes Complexity**: Start with staging environment, iterate to production
- **ML Model Performance**: Use pre-trained models initially, fine-tune later
- **Testing Time**: Parallelize test execution, use cloud test infrastructure
- **Documentation Scope**: Phase migration by priority, iterate on quality

---

## Budget & Resources

### Infrastructure Costs (Monthly)

| Service | Estimated Cost |
|---------|---------------|
| Kubernetes Cluster (3-node) | $400-600 |
| Cloud Load Balancer | $50-100 |
| Database (managed PostgreSQL) | $200-400 |
| Redis (managed) | $100-200 |
| Monitoring (Grafana Cloud) | $50-100 |
| WAF/DDoS Protection | $100-200 |
| **Total** | **$900-1600/month** |

### Staffing

- **Backend Engineers**: 2 FTE (testing, infrastructure)
- **Mobile Engineers**: 1 FTE (parity, performance)
- **ML/Data Engineer**: 0.5 FTE (analytics, moderation)
- **DevOps Engineer**: 1 FTE (K8s, monitoring)
- **Technical Writer**: 0.5 FTE (documentation)

### Training & Tools

- Kubernetes certification courses: $1,000
- Load testing infrastructure (k6 Cloud): $200/month
- OpenAI API credits (embeddings): $500/month
- Total: ~$2,700 one-time + $700/month

---

## Communication & Reporting

### Weekly Standups
- **Time**: Mondays 9:00 AM
- **Attendees**: Engineering team + Product
- **Format**: Progress, blockers, next steps

### Bi-Weekly Reviews
- **Time**: Fridays 2:00 PM (every 2 weeks)
- **Attendees**: Full team + stakeholders
- **Format**: Demo completed work, metrics review, retrospective

### Monthly Business Reviews
- **Audience**: Leadership team
- **Metrics**: Testing coverage %, mobile adoption, infrastructure uptime
- **Format**: Written report + presentation

### Issue Tracking
- All issues in GitHub with labels: `roadmap-5.0`, `P0/P1/P2/P3`, area tags
- Milestones: Phase 1, Phase 2, etc.
- Projects board: Kanban view with swim lanes per phase

---

## Appendix: Roadmap Evolution

### Roadmap 1.0-3.0
- **Focus**: Initial development, feature delivery, MVP launch
- **Outcome**: 66 features implemented, 97% completion

### Roadmap 4.0
- **Focus**: Sequential delivery of remaining features
- **Outcome**: Security hardening, infrastructure setup, launch prep completed

### Roadmap 5.0 (Current)
- **Focus**: Testing, mobile parity, infrastructure excellence
- **Outcome**: Production-ready platform with 90%+ test coverage, mobile maturity, operational excellence

### Roadmap 6.0 (Future)
- **Potential Focus**: International expansion, advanced social features, revenue growth
- **Timeline**: Q3-Q4 2026

---

## Related Documentation

- [Roadmap 4.0](./roadmap-4.0.md) - Feature development roadmap
- [Feature Inventory](./feature-inventory.md) - Complete platform feature audit
- [Testing Strategy](../TESTING.md) - Comprehensive testing approach
- [Infrastructure Architecture](../backend/architecture.md) - System design
- [API Documentation](../backend/api.md) - API reference

---

**Last Updated**: 2025-12-24
**Next Review**: 2026-01-15
**Owner**: @onnwee
**Status**: Active Development

---

*Roadmap 5.0 represents our commitment to platform excellence, reliability, and long-term sustainability. Every issue is scoped for automated coding agents with detailed acceptance criteria and clear dependencies.*
