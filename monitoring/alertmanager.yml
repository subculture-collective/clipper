global:
  resolve_timeout: 5m
  # SMTP configuration for email alerts
  # smtp_smarthost: 'smtp.gmail.com:587'
  # smtp_from: 'alerts@clipper.app'
  # smtp_auth_username: 'alerts@clipper.app'
  # smtp_auth_password: 'your-smtp-password'
  # smtp_require_tls: true

# Template files for custom alert formatting
templates:
  - '/etc/alertmanager/templates/*.tmpl'

# Main routing tree
route:
  receiver: 'default'
  group_by: ['alertname', 'cluster', 'service']
  group_wait: 10s      # Wait for other alerts in group
  group_interval: 5m   # Time between group notifications
  repeat_interval: 4h  # Time before re-sending notification

  # Route tree for different alert types
  routes:
    # Critical (P1) alerts - immediate response required
    - match:
        severity: critical
      receiver: 'pagerduty-critical'
      group_wait: 10s
      group_interval: 5m
      repeat_interval: 15m
      continue: true  # Also send to other receivers

    - match:
        severity: critical
      receiver: 'slack-incidents'
      group_wait: 10s
      group_interval: 5m
      repeat_interval: 1h

    # SLO breach alerts - high priority
    - match_re:
        alertname: '^SLO.*Breach$'
      receiver: 'pagerduty-slo'
      group_wait: 10s
      group_interval: 5m
      repeat_interval: 30m
      continue: true

    - match_re:
        alertname: '^SLO.*Breach$'
      receiver: 'slack-incidents'
      group_wait: 10s
      repeat_interval: 1h

    # Security alerts - immediate attention
    - match:
        security: 'true'
      receiver: 'pagerduty-security'
      group_wait: 5s
      group_interval: 5m
      repeat_interval: 15m
      continue: true

    - match:
        security: 'true'
      receiver: 'slack-security'
      group_wait: 5s
      repeat_interval: 30m

    # Error budget alerts
    - match_re:
        alertname: '^ErrorBudget.*Burn$'
      receiver: 'slack-incidents'
      group_wait: 30s
      repeat_interval: 1h

    # Warning (P2) alerts - less urgent
    - match:
        severity: warning
      receiver: 'slack-alerts'
      group_wait: 5m
      group_interval: 10m
      repeat_interval: 4h

    # Info (P3) alerts - informational only
    - match:
        severity: info
      receiver: 'slack-monitoring'
      group_wait: 10m
      group_interval: 30m
      repeat_interval: 12h

# Alert receivers (notification destinations)
receivers:
  # Default fallback receiver
  - name: 'default'
    slack_configs:
      - api_url: 'https://hooks.slack.com/services/YOUR/SLACK/WEBHOOK'
        channel: '#alerts'
        title: '{{ .GroupLabels.alertname }}'
        text: '{{ range .Alerts }}{{ .Annotations.description }}{{ end }}'

  # PagerDuty for critical alerts
  - name: 'pagerduty-critical'
    pagerduty_configs:
      - service_key: 'YOUR_PAGERDUTY_SERVICE_KEY'
        description: '{{ .GroupLabels.alertname }}: {{ .CommonAnnotations.summary }}'
        severity: '{{ .CommonLabels.severity }}'
        details:
          firing: '{{ .Alerts.Firing | len }}'
          resolved: '{{ .Alerts.Resolved | len }}'
          description: '{{ .CommonAnnotations.description }}'
          runbook: '{{ .CommonAnnotations.runbook }}'

  # PagerDuty for SLO breaches
  - name: 'pagerduty-slo'
    pagerduty_configs:
      - service_key: 'YOUR_PAGERDUTY_SLO_SERVICE_KEY'
        description: 'SLO Breach: {{ .GroupLabels.alertname }}'
        severity: 'critical'
        details:
          slo_type: '{{ .CommonLabels.slo }}'
          description: '{{ .CommonAnnotations.description }}'
          runbook: 'docs/operations/playbooks/slo-breach-response.md'

  # PagerDuty for security alerts
  - name: 'pagerduty-security'
    pagerduty_configs:
      - service_key: 'YOUR_PAGERDUTY_SECURITY_SERVICE_KEY'
        description: 'Security Alert: {{ .GroupLabels.alertname }}'
        severity: 'critical'
        details:
          description: '{{ .CommonAnnotations.description }}'
          runbook: '{{ .CommonAnnotations.runbook }}'

  # Slack for critical incidents
  - name: 'slack-incidents'
    slack_configs:
      - api_url: 'https://hooks.slack.com/services/YOUR/SLACK/WEBHOOK'
        channel: '#incidents'
        username: 'Alertmanager'
        icon_emoji: ':fire:'
        title: 'üö® {{ .CommonLabels.severity | toUpper }}: {{ .GroupLabels.alertname }}'
        text: |-
          {{ range .Alerts }}
          *Alert:* {{ .Labels.alertname }}
          *Severity:* {{ .Labels.severity }}
          *Summary:* {{ .Annotations.summary }}
          *Description:* {{ .Annotations.description }}
          {{ if .Annotations.runbook }}*Runbook:* {{ .Annotations.runbook }}{{ end }}
          *Source:* {{ .GeneratorURL }}
          {{ end }}
        send_resolved: true
        actions:
          - type: button
            text: 'View in Grafana'
            url: 'http://localhost:3000/d/slo-dashboard'
          - type: button
            text: 'View in Prometheus'
            url: '{{ (index .Alerts 0).GeneratorURL }}'

  # Slack for security alerts
  - name: 'slack-security'
    slack_configs:
      - api_url: 'https://hooks.slack.com/services/YOUR/SLACK/WEBHOOK'
        channel: '#security'
        username: 'Security Alertmanager'
        icon_emoji: ':shield:'
        title: 'üõ°Ô∏è Security Alert: {{ .GroupLabels.alertname }}'
        text: |-
          {{ range .Alerts }}
          *Alert:* {{ .Labels.alertname }}
          *Summary:* {{ .Annotations.summary }}
          *Description:* {{ .Annotations.description }}
          {{ if .Annotations.runbook }}*Runbook:* {{ .Annotations.runbook }}{{ end }}
          {{ end }}
        send_resolved: true

  # Slack for warning alerts
  - name: 'slack-alerts'
    slack_configs:
      - api_url: 'https://hooks.slack.com/services/YOUR/SLACK/WEBHOOK'
        channel: '#alerts'
        username: 'Alertmanager'
        icon_emoji: ':warning:'
        title: '‚ö†Ô∏è {{ .GroupLabels.alertname }}'
        text: |-
          {{ range .Alerts }}
          *Summary:* {{ .Annotations.summary }}
          *Description:* {{ .Annotations.description }}
          {{ end }}
        send_resolved: true

  # Slack for informational alerts
  - name: 'slack-monitoring'
    slack_configs:
      - api_url: 'https://hooks.slack.com/services/YOUR/SLACK/WEBHOOK'
        channel: '#monitoring'
        username: 'Monitoring Bot'
        icon_emoji: ':chart_with_upwards_trend:'
        title: '‚ÑπÔ∏è {{ .GroupLabels.alertname }}'
        text: '{{ .CommonAnnotations.description }}'
        send_resolved: false

  # Email for critical alerts (backup)
  - name: 'email-oncall'
    email_configs:
      - to: 'oncall@clipper.app'
        from: 'alerts@clipper.app'
        subject: '[{{ .CommonLabels.severity | toUpper }}] {{ .GroupLabels.alertname }}'
        html: |
          <h2>{{ .CommonLabels.severity | toUpper }}: {{ .GroupLabels.alertname }}</h2>
          {{ range .Alerts }}
          <p><strong>Summary:</strong> {{ .Annotations.summary }}</p>
          <p><strong>Description:</strong> {{ .Annotations.description }}</p>
          {{ if .Annotations.runbook }}<p><strong>Runbook:</strong> {{ .Annotations.runbook }}</p>{{ end }}
          <p><strong>Source:</strong> <a href="{{ .GeneratorURL }}">View in Prometheus</a></p>
          {{ end }}

  # Discord webhook (optional)
  - name: 'discord-alerts'
    webhook_configs:
      - url: 'https://discord.com/api/webhooks/YOUR/WEBHOOK'
        send_resolved: true

# Inhibition rules - prevent alert spam
inhibit_rules:
  # If a critical alert is firing, suppress warnings for same alert
  - source_matchers:
      - severity = critical
    target_matchers:
      - severity =~ warning|info
    equal:
      - alertname
      - cluster
      - service

  # If service is down, suppress other alerts from that service
  - source_matchers:
      - alertname = ServiceDown
    target_matchers:
      - severity =~ warning|info
    equal:
      - job
      - instance

  # If SLO breach, suppress individual error rate alerts
  - source_matchers:
      - alertname = SLOErrorRateBreach
    target_matchers:
      - alertname = HighErrorRate
    equal:
      - job

  # If database is down, suppress connection alerts
  - source_matchers:
      - alertname = DatabaseDown
    target_matchers:
      - alertname = DatabaseConnectionIssues

  # If Redis is down, suppress memory alerts
  - source_matchers:
      - alertname = RedisDown
    target_matchers:
      - alertname =~ Redis.*
