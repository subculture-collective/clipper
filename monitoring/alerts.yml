# Prometheus Alert Rules for Clipper
# Place this file in /opt/clipper/monitoring/alerts.yml
#
# These alerts are based on defined SLOs:
# - Availability: 99.5% uptime
# - Latency: P95 < 100ms (list), P95 < 50ms (detail)
# - Error Rate: < 0.5%

groups:
  - name: clipper_slo_alerts
    interval: 30s
    rules:
      # SLO: Availability - 99.5% uptime
      - alert: SLOAvailabilityBreach
        expr: |
          (
            1 - (sum(rate(http_requests_total{status=~"2.."}[5m])) / sum(rate(http_requests_total[5m])))
          ) > 0.005
        for: 5m
        labels:
          severity: critical
          slo: availability
        annotations:
          summary: "Availability SLO breach"
          description: "Service availability is {{ $value | humanizePercentage }}, target is 99.5%."
          runbook: "Check service health, investigate errors, consider rollback."

      # SLO: Error Rate - < 0.5%
      - alert: SLOErrorRateBreach
        expr: |
          (
            sum(rate(http_requests_total{status=~"5.."}[5m])) / sum(rate(http_requests_total[5m]))
          ) > 0.005
        for: 5m
        labels:
          severity: critical
          slo: error_rate
        annotations:
          summary: "Error rate SLO breach"
          description: "Error rate is {{ $value | humanizePercentage }}, target is < 0.5%."
          runbook: "Check error logs, identify error patterns, apply fix or rollback."

      # SLO: Latency - P95 < 100ms for list endpoints
      - alert: SLOLatencyBreach
        expr: |
          histogram_quantile(0.95,
            sum(rate(http_request_duration_seconds_bucket{path=~"/api/v1/(clips|feed|lists).*"}[5m])) by (le)
          ) > 0.1
        for: 5m
        labels:
          severity: warning
          slo: latency
        annotations:
          summary: "Latency SLO breach for list endpoints"
          description: "P95 latency is {{ $value }}s, target is < 0.1s."
          runbook: "Check database query performance, Redis cache hit rate, system resources."

      # Error Budget: Fast burn (> 10% in 1 hour)
      - alert: ErrorBudgetFastBurn
        expr: |
          (
            1 - (sum(rate(http_requests_total{status=~"2.."}[1h])) / sum(rate(http_requests_total[1h])))
          ) > 0.1
        for: 5m
        labels:
          severity: critical
          error_budget: fast_burn
        annotations:
          summary: "Error budget fast burn detected"
          description: "Consuming > 10% error budget in 1 hour. Current availability: {{ $value | humanizePercentage }}."
          runbook: "Immediate action required. Investigate and mitigate ongoing issues."

      # Error Budget: Medium burn (> 25% in 6 hours)
      - alert: ErrorBudgetMediumBurn
        expr: |
          (
            1 - (sum(rate(http_requests_total{status=~"2.."}[6h])) / sum(rate(http_requests_total[6h])))
          ) > 0.25
        for: 15m
        labels:
          severity: warning
          error_budget: medium_burn
        annotations:
          summary: "Error budget medium burn detected"
          description: "Consuming > 25% error budget in 6 hours. Current availability: {{ $value | humanizePercentage }}."
          runbook: "Review recent changes, implement stability improvements."

  - name: clipper_service_alerts
    interval: 30s
    rules:
      # Service Down
      - alert: ServiceDown
        expr: up == 0
        for: 1m
        labels:
          severity: critical
        annotations:
          summary: "Service {{ $labels.job }} is down"
          description: "{{ $labels.job }} has been down for more than 1 minute."

      # High Error Rate
      - alert: HighErrorRate
        expr: |
          (
            sum(rate(http_requests_total{status=~"5.."}[5m])) by (job)
            /
            sum(rate(http_requests_total[5m])) by (job)
          ) > 0.05
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "High error rate on {{ $labels.job }}"
          description: "{{ $labels.job }} has an error rate of {{ $value | humanizePercentage }} over the last 5 minutes."

      # High Response Time
      - alert: HighResponseTime
        expr: |
          histogram_quantile(0.95,
            sum(rate(http_request_duration_seconds_bucket[5m])) by (job, le)
          ) > 0.5
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "High response time on {{ $labels.job }}"
          description: "{{ $labels.job }} 95th percentile response time is {{ $value }}s."

  - name: clipper_resource_alerts
    interval: 30s
    rules:
      # High CPU Usage
      - alert: HighCPUUsage
        expr: |
          100 - (avg by (instance) (irate(node_cpu_seconds_total{mode="idle"}[5m])) * 100) > 80
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "High CPU usage on {{ $labels.instance }}"
          description: "CPU usage is {{ $value | humanize }}% on {{ $labels.instance }}."

      # High Memory Usage
      - alert: HighMemoryUsage
        expr: |
          (
            node_memory_MemTotal_bytes - node_memory_MemAvailable_bytes
          ) / node_memory_MemTotal_bytes * 100 > 80
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "High memory usage on {{ $labels.instance }}"
          description: "Memory usage is {{ $value | humanize }}% on {{ $labels.instance }}."

      # Low Disk Space
      - alert: LowDiskSpace
        expr: |
          (
            node_filesystem_avail_bytes{mountpoint="/"}
            / node_filesystem_size_bytes{mountpoint="/"}
          ) * 100 < 20
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "Low disk space on {{ $labels.instance }}"
          description: "Disk space is {{ $value | humanize }}% free on {{ $labels.instance }}."

      # Critical Disk Space
      - alert: CriticalDiskSpace
        expr: |
          (
            node_filesystem_avail_bytes{mountpoint="/"}
            / node_filesystem_size_bytes{mountpoint="/"}
          ) * 100 < 10
        for: 1m
        labels:
          severity: critical
        annotations:
          summary: "Critical disk space on {{ $labels.instance }}"
          description: "Disk space is {{ $value | humanize }}% free on {{ $labels.instance }}."

  - name: clipper_database_alerts
    interval: 30s
    rules:
      # Database Connection Issues
      - alert: DatabaseConnectionIssues
        expr: |
          sum(pg_stat_database_numbackends) by (datname) > 80
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "High number of database connections"
          description: "Database {{ $labels.datname }} has {{ $value }} active connections."

      # Database Down
      - alert: DatabaseDown
        expr: pg_up == 0
        for: 1m
        labels:
          severity: critical
        annotations:
          summary: "PostgreSQL is down"
          description: "PostgreSQL database is not responding."

      # Slow Queries
      - alert: SlowQueries
        expr: |
          rate(pg_stat_activity_max_tx_duration[5m]) > 30
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "Slow database queries detected"
          description: "Database has queries taking more than 30 seconds."

  - name: clipper_redis_alerts
    interval: 30s
    rules:
      # Redis Down
      - alert: RedisDown
        expr: redis_up == 0
        for: 1m
        labels:
          severity: critical
        annotations:
          summary: "Redis is down"
          description: "Redis cache is not responding."

      # High Redis Memory Usage
      - alert: HighRedisMemoryUsage
        expr: |
          (redis_memory_used_bytes / redis_memory_max_bytes) * 100 > 80
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "High Redis memory usage"
          description: "Redis is using {{ $value | humanize }}% of allocated memory."

      # Low Cache Hit Rate
      - alert: LowCacheHitRate
        expr: |
          (
            rate(redis_keyspace_hits_total[5m])
            / (rate(redis_keyspace_hits_total[5m]) + rate(redis_keyspace_misses_total[5m]))
          ) < 0.8
        for: 10m
        labels:
          severity: info
        annotations:
          summary: "Low Redis cache hit rate"
          description: "Redis cache hit rate is {{ $value | humanizePercentage }}."

  - name: clipper_ssl_alerts
    interval: 1d
    rules:
      # SSL Certificate Expiring Soon
      - alert: SSLCertificateExpiringSoon
        expr: |
          (ssl_certificate_expiry_seconds - time()) / 86400 < 30
        for: 1h
        labels:
          severity: warning
        annotations:
          summary: "SSL certificate expiring soon"
          description: "SSL certificate for {{ $labels.domain }} expires in {{ $value }} days."

      # SSL Certificate Expired
      - alert: SSLCertificateExpired
        expr: |
          (ssl_certificate_expiry_seconds - time()) < 0
        for: 1m
        labels:
          severity: critical
        annotations:
          summary: "SSL certificate expired"
          description: "SSL certificate for {{ $labels.domain }} has expired."
